{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe12c203-e6a6-452c-a655-afb8a03a4ff5",
   "metadata": {},
   "source": [
    "# End of week 1 exercise\n",
    "\n",
    "To demonstrate your familiarity with OpenAI API, and also Ollama, build a tool that takes a technical question,  \n",
    "and responds with an explanation. This is a tool that you will be able to use yourself during the course!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1070317-3ed9-4659-abe3-828943230e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from IPython.display import Markdown, display, update_display\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a456906-915a-4bfd-bb9d-57e505c5093f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# constants\n",
    "\n",
    "MODEL_GPT = 'gpt-4o-mini'\n",
    "MODEL_LLAMA = 'llama3.2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d7923c-5f28-4c30-8556-342d7c8497c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up environment\n",
    "\n",
    "load_dotenv()\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "if openai_api_key is None:\n",
    "    raise ValueError(\"OPENAI_API_KEY environment variable not set.\")\n",
    "\n",
    "system_prompt = \"\"\"\n",
    "You are a helpful assistant. You will be given a task and you should respond with the best possible answer. Ensure that your response is clear, concise, and relevant to the task at hand. If you are unsure about something, ask for clarification. \n",
    "Please assume I don't know anything about the task and provide a detailed explanation.\"\"\"\n",
    "\n",
    "openai = OpenAI(api_key=openai_api_key)\n",
    "ollama = OpenAI(base_url='http://localhost:11434/v1', api_key='ollama')\n",
    "\n",
    "def answer_question(question, model):\n",
    "    \"\"\"\n",
    "    Function to answer a question using OpenAI's API or Ollama.\n",
    "    \"\"\"\n",
    "   \n",
    "    llm_query = [\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": question}]\n",
    "            \n",
    "    stream = None\n",
    "    if model == MODEL_LLAMA:\n",
    "        # Use the Llama model\n",
    "        stream = ollama.chat.completions.create(\n",
    "            model=model,\n",
    "            messages= llm_query,\n",
    "            stream=True)\n",
    "    elif model == MODEL_GPT:\n",
    "         # Call the OpenAI API\n",
    "        stream = openai.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=llm_query,\n",
    "            stream=True)\n",
    "    else:\n",
    "        raise ValueError(\"Invalid model specified. Use 'gpt' or 'llama'.\")\n",
    "    \n",
    "    message = \"\"\n",
    "    display_handle = display(Markdown(\"\"), display_id=True)\n",
    "    for chunk in (stream or []):\n",
    "        message += chunk.choices[0].delta.content or ''\n",
    "        message = message.replace(\"```\",\"\").replace(\"markdown\", \"\")\n",
    "        update_display(Markdown(message), display_id=display_handle.display_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f0d0137-52b0-47a8-81a8-11a90a010798",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here is the question; type over this to ask something new\n",
    "\n",
    "question = \"\"\"\n",
    "Please explain what this code does and why:\n",
    "yield from {book.get(\"author\") for book in books if book.get(\"author\")}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ce7000-a4a5-4cce-a261-e75ef45063b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get gpt-4o-mini to answer, with streaming\n",
    "answer_question(question, MODEL_GPT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74b54865",
   "metadata": {},
   "source": [
    "## Runo Ollama from terminal\n",
    "\n",
    "Open a terminal and launch \n",
    "\n",
    "ollama serve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f7c8ea8-4082-4ad0-8751-3301adcf6538",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Llama 3.2 to answer\n",
    "answer_question(question, MODEL_LLAMA)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llms",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
